# SparkStreamImoocLog
1.Python日志产生器开发，使用Linux的crontab设置定时任务；  
2.使用Flume实时收集日志信息，对接实时日志数据到Kafka；     
3.使用spark-stream API进行数据清洗，实现对每日不同课程点击率和不同referer的访问量的统计，记录数据到HBase。  


